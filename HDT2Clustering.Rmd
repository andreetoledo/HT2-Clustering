---
title: "Clustering, HDT2"
author: "Ayleen Rubio 19003, Andrés Say 19705. Andreé Toledo 18439"
date: "23/02/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#"C:/Users/andre/OneDrive/Documentos/HT1.Analisis-Exploratorio"
#Ingebor Rubio/Desktop/Trabajos/Quinto Semestre/Mineria/HDT1

knitr::opts_knit$set(root.dir="C:/Users/Andree/Documents/GitHub/HT1.Analisis-Exploratorio")

install.packages("ppclust")
library(ppclust)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el n?mero de clusters ?ptimo
library(factoextra) #Para hacer gr?ficos bonitos de clustering

```

# Clustering sobre base de datos de películas  
## Análisis exploratorio de los datos
En este informe usted podrá leer los hallazgos de EDA, a continuación se muestra el resumen de los datos:

```{r movies, echo=FALSE}
sum_movies <- read.csv("tmdb-movies.csv")
summary(sum_movies)
```

En el siguiente cuadro se muestra el tipo de dato de cada variable:

```{r data, echo=FALSE}
str(sum_movies)
```

### Preprocesamiento de datos  
En primer lugar, es necesario hacer un complete cases para ignorar aquellos casos en los que las variables se encuentren como N/A.

```{r preprocesamiento, echo=FALSE}
datosCompletos<- sum_movies[complete.cases(sum_movies),]
datos <- datosCompletos[,c(3,4,5,13,17,19)]
```

Se trabajará con las siguientes variables que tienen formato int para formas grupos: Popularity, budget, revenue, runtime, vote_count, release_year. Esto debido a que son variables que se pueden clasificar por grupos y los resultados pueden ser interpretados.

Para saber la mejor cantidad de clusters a utilizar, se hará lo siguiente:
```{r cantClusters, echo=FALSE}
wss <- (nrow(datos[,1:6])-1)*sum(apply(datos[,1:6],2,var))

for (i in 2:10) 
  wss[i] <- sum(kmeans(datos[,1:6], centers=i)$withinss)

plot(1:10, wss, type="b", xlab="Number of Clusters",  ylab="Within groups sum of squares")

```

Puede observarse en el gráfico que el codo se encuentra en el valor 3, por lo que esta es la cantidad adecuada de clusters que se deben utilizar.

## Agrupamiento por medio de k-means  
```{r kmeans, echo=FALSE}
km<-kmeans(datos[,1:6],3,iter.max =100)
datos$grupo<-km$cluster

plotcluster(datos[,1:6],km$cluster)

```
Se puede observar cómo es que se han dividido los tres grupos, siendo el primero el de color negro, el segundo el de color rojo y el tercero el de color verde. Al momento de cambiar de un grupo a otro, puede haber una ligera confusión ya que algunos objetos de un grupo, se encuentran en otro.

## Agrupamiento por medio de clustering jerárquico
```{r jerarquico, echo=FALSE}
hc<-hclust(dist(datos[,1:6])) #Genera el clustering jerárquico de los datos
hc
plot(hc) #Genera el dendograma
rect.hclust(hc,k=3) #Dibuja el corte de los grupos en el gráfico
groups<-cutree(hc,k=3) #corta el dendograma, determinando el grupo de cada fila
datos$gruposHC<-groups


g1HC<-datos[datos$gruposHC==1,]
g2HC<-datos[datos$gruposHC==2,]
g3HC<-datos[datos$gruposHC==3,]

```
Este diagrama es más complicado de interpretar, ya que cuenta con 10866 objetos, razón por la cual no se logra observar el último grupo en el que se ha dividido.


## Fuzzy C-means
```{r fuzzy}
fcm<-cmeans(datos[,1:6],3)
datos$FCGrupos<-fcm$cluster
datos<-cbind(datos,fcm$membership)
res.fcm <- fcm(datos, centers=3)
res.fcm3 <- ppclust2(res.fcm,"fanny")
cluster::clusplot(scale(datsos), res.fcm3$cluster, main = "Fuzzy C-means para datos sobre películas",
                  color = TRUE, labels = 2, lines = 2, cex= 1)

```

## Mixture of gaussians
```{r gaussians, echo = FALSE}
mc<-Mclust(datos[,1:6],3)
plot(mc, what = "classification", main="MClust Classification")
datos$mxGau<-mc$classification
g1MC<-datos[datos$mxGau==1,]
g2MC<-datos[datos$mxGau==2,]
g3MC<-datos[datos$mxGau==3,]
```
Es este gráfico puede observarse cómo es que para cada combinación de variables cuál es la combinación de los grupos


### Comparación de resultados de agrupamientos  
Insertar comparación acá

## Calidad del agrupamiento
### K-means
```{r calk, echo=FALSE}
silkm<-silhouette(km$cluster,dist(datos[,1:6]))
mean(silkm[,3])
```

### Cluster jerárquico
```{r caljer, echo=FALSE}
silch<-silhouette(groups,dist(datos[,1:6]))
mean(silch[,3])

```

### Fuzzy C-means
```{r calfuzzy, echo=FALSE}
silfcm<-silhouette(fcm$cluster,dist(datos[,1:6]))
mean(silfcm[,3])
```

### Mixture of gaussians
```{r calGau, echo=FALSE}
silmg<-silhouette(mc$classification,dist(datos[,1:6]))
mean(silmg[,3])
```

Según los valores obtenidos, el que cuenta con la mayor silueta es el cluster jerárquico con un valor de 0.912, por esta razón, se utilizará este método de agrupamiento para explorar e interpretar los grupos.

## Visualizar el cluster jerárquico
```{r visJer, echo=FALSE}
#hc.cut<-hcut(datos[,1:6], k=3, hc_method = "complete")
#fviz_dend(hc.cut, show_labels = FALSE, rect = TRUE)
#fviz_cluster(hc.cut, ellipse.type = "convex")
```
#Se aplico el agrupamiento Jerárquico, denograma sin recorte de filas.
```{r algoritmoHierarchical, echo=FALSE}
library(ggdendro)
dendrogram <- hclust(dist(sum_movies, method = 'euclidean'), method = 'ward.D')
ggdendrogram(dendrogram, rotate = FALSE, labels = FALSE, theme_dendro = TRUE) + 
  labs(title = "Dendrograma")

```
